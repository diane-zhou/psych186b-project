{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18f7a7a",
   "metadata": {},
   "source": [
    "### webscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a030e89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main URL:             https://www.rottentomatoes.com/m/parasite_2019\n",
      "Critic reviews URL:   https://www.rottentomatoes.com/m/parasite_2019/reviews\n",
      "Audience reviews URL: https://www.rottentomatoes.com/m/parasite_2019/reviews/verified-audience\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'googlechromelabs.github.io'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'googlechromelabs.github.io'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping RT movie info...\n",
      "Getting scores from reviews page JSON...\n",
      "Title: Parasite | Tomatometer: 99% | Popcornmeter: N/A\n",
      "\n",
      "Scraping critic reviews...\n",
      "  Collected 20 critic reviews so far...\n",
      "  Collected 40 critic reviews so far...\n",
      "  Collected 60 critic reviews so far...\n",
      "\n",
      "Scraping audience reviews...\n",
      "  Collected 10 audience reviews so far...\n",
      "  Collected 30 audience reviews so far...\n",
      "  Collected 50 audience reviews so far...\n",
      "\n",
      "Total: 50 critic + 50 audience = 100 reviews\n",
      "Saved to: /Users/Diane/Desktop/PSYCH 186B/project/reviews_Parasite_RT.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['WDM_SSL_VERIFY'] = '0'\n",
    "os.environ['WDM_TIMEOUT'] = '300'\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "\n",
    "def make_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "\n",
    "def get_rt_movie_info(driver, main_url, critic_reviews_url):\n",
    "    print(\"Scraping RT movie info...\")\n",
    "\n",
    "    # Get title from main page\n",
    "    driver.get(main_url)\n",
    "    time.sleep(8)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    title_tag = soup.find(\"h1\")\n",
    "    title = title_tag.get_text(strip=True) if title_tag else \"N/A\"\n",
    "\n",
    "    # Get scores from critic reviews page JSON â€” we know they're embedded there\n",
    "    print(\"Getting scores from reviews page JSON...\")\n",
    "    driver.get(critic_reviews_url)\n",
    "    time.sleep(8)\n",
    "    page_text = driver.page_source\n",
    "\n",
    "    tomatometer = \"N/A\"\n",
    "    popcornmeter = \"N/A\"\n",
    "\n",
    "    # Extract from embedded JSON: \"tomatometerScore\":{\"state\":\"certified-fresh\",\"value\":99}\n",
    "    t_match = re.search(r'\"tomatometerScore\"\\s*:\\s*\\{[^}]*\"value\"\\s*:\\s*(\\d+)', page_text)\n",
    "    if t_match:\n",
    "        tomatometer = t_match.group(1) + \"%\"\n",
    "\n",
    "    # Extract from embedded JSON: \"audienceScore\":{\"value\":90}\n",
    "    a_match = re.search(r'\"audienceScore\"\\s*:\\s*\\{[^}]*\"value\"\\s*:\\s*(\\d+)', page_text)\n",
    "    if a_match:\n",
    "        popcornmeter = a_match.group(1) + \"%\"\n",
    "\n",
    "    print(f\"Title: {title} | Tomatometer: {tomatometer} | Popcornmeter: {popcornmeter}\")\n",
    "    return {\"title\": title, \"tomatometer\": tomatometer, \"popcornmeter\": popcornmeter}\n",
    "\n",
    "\n",
    "def parse_review_cards(soup, review_type):\n",
    "    reviews = []\n",
    "    cards = soup.find_all(\"review-card\")\n",
    "\n",
    "    for card in cards:\n",
    "        review = {}\n",
    "        review[\"review_type\"] = review_type\n",
    "\n",
    "        # Reviewer name\n",
    "        name_tag = card.find(attrs={\"slot\": \"name\"})\n",
    "        review[\"reviewer\"] = name_tag.get_text(strip=True) if name_tag else \"N/A\"\n",
    "\n",
    "        # Publication\n",
    "        pub_tag = card.find(attrs={\"slot\": \"publication\"})\n",
    "        review[\"publication\"] = pub_tag.get_text(strip=True) if pub_tag else \"N/A\"\n",
    "\n",
    "        # Score\n",
    "        rating_slot = card.find(attrs={\"slot\": \"rating\"})\n",
    "        if rating_slot:\n",
    "            stars = rating_slot.find(\"rating-stars-group\")\n",
    "            if stars:\n",
    "                review[\"score\"] = stars.get(\"score\", \"N/A\") + \"/5\"\n",
    "            else:\n",
    "                inner_span = rating_slot.find(\"span\", style=lambda s: s and \"margin-top\" in s)\n",
    "                score_text = inner_span.get_text(strip=True) if inner_span else \"\"\n",
    "                review[\"score\"] = score_text if score_text else \"N/A\"\n",
    "        else:\n",
    "            review[\"score\"] = \"N/A\"\n",
    "\n",
    "        # Review text\n",
    "        text_tag = card.find(attrs={\"slot\": \"review\"})\n",
    "        review[\"review_text\"] = text_tag.get_text(strip=True) if text_tag else \"N/A\"\n",
    "\n",
    "        # Date\n",
    "        date_tag = card.find(attrs={\"slot\": \"timestamp\"})\n",
    "        review[\"date\"] = date_tag.get_text(strip=True) if date_tag else \"N/A\"\n",
    "\n",
    "        if review[\"reviewer\"] != \"N/A\" or review[\"review_text\"] != \"N/A\":\n",
    "            reviews.append(review)\n",
    "\n",
    "    return reviews\n",
    "\n",
    "\n",
    "def scrape_rt_reviews(driver, reviews_url, review_type, max_reviews=50):\n",
    "    print(f\"\\nScraping {review_type} reviews...\")\n",
    "    driver.get(reviews_url)\n",
    "    time.sleep(8)\n",
    "\n",
    "    all_reviews = []\n",
    "\n",
    "    while True:\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        all_reviews = parse_review_cards(soup, review_type)\n",
    "        print(f\"  Collected {len(all_reviews)} {review_type} reviews so far...\")\n",
    "\n",
    "        if len(all_reviews) >= max_reviews:\n",
    "            break\n",
    "\n",
    "        clicked = False\n",
    "        for selector in [\"[data-qa='load-more-btn']\", \"rt-button[data-qa='load-more']\", \"button.load-more-btn\"]:\n",
    "            try:\n",
    "                load_more = WebDriverWait(driver, 5).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].click();\", load_more)\n",
    "                time.sleep(3)\n",
    "                clicked = True\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if not clicked:\n",
    "            try:\n",
    "                load_more = driver.find_element(By.XPATH, \"//rt-button[contains(., 'Load More')] | //button[contains(., 'Load More')]\")\n",
    "                driver.execute_script(\"arguments[0].click();\", load_more)\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                print(f\"  No more {review_type} reviews to load.\")\n",
    "                break\n",
    "\n",
    "    return all_reviews[:max_reviews]\n",
    "\n",
    "\n",
    "# ---- MAIN ----\n",
    "MAIN_URL = input(\"Enter the Rotten Tomatoes movie URL (e.g. https://www.rottentomatoes.com/m/parasite_2019): \").strip()\n",
    "\n",
    "base_url = MAIN_URL.rstrip(\"/\")\n",
    "CRITIC_REVIEWS_URL = f\"{base_url}/reviews\"\n",
    "AUDIENCE_REVIEWS_URL = f\"{base_url}/reviews/verified-audience\"\n",
    "\n",
    "print(f\"\\nMain URL:             {MAIN_URL}\")\n",
    "print(f\"Critic reviews URL:   {CRITIC_REVIEWS_URL}\")\n",
    "print(f\"Audience reviews URL: {AUDIENCE_REVIEWS_URL}\\n\")\n",
    "\n",
    "driver = make_driver()\n",
    "\n",
    "movie_info = get_rt_movie_info(driver, MAIN_URL, CRITIC_REVIEWS_URL)\n",
    "critic_reviews = scrape_rt_reviews(driver, CRITIC_REVIEWS_URL, \"critic\", max_reviews=50)\n",
    "audience_reviews = scrape_rt_reviews(driver, AUDIENCE_REVIEWS_URL, \"audience\", max_reviews=50)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "all_reviews = critic_reviews + audience_reviews\n",
    "print(f\"\\nTotal: {len(critic_reviews)} critic + {len(audience_reviews)} audience = {len(all_reviews)} reviews\")\n",
    "\n",
    "for review in all_reviews:\n",
    "    review[\"movie_title\"] = movie_info[\"title\"]\n",
    "    review[\"tomatometer\"] = movie_info[\"tomatometer\"]\n",
    "    review[\"popcornmeter\"] = movie_info[\"popcornmeter\"]\n",
    "\n",
    "safe_title = re.sub(r'[^\\w\\s-]', '', movie_info['title']).strip().replace(' ', '_')\n",
    "filename = f\"reviews_{safe_title}_RT.csv\"\n",
    "filepath = os.path.join(\"/Users/Diane/Desktop/PSYCH 186B/project\", filename)\n",
    "\n",
    "with open(filepath, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    fieldnames = [\"movie_title\",\n",
    "                  \"review_type\", \"reviewer\", \"publication\", \"score\", \"date\", \"review_text\"]\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_reviews)\n",
    "\n",
    "print(f\"Saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce0607",
   "metadata": {},
   "source": [
    "### debug code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "687ac3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'googlechromelabs.github.io'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'googlechromelabs.github.io'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITIC PAGE - Found 20 cards\n",
      "First critic card slot='rating' raw HTML:\n",
      "<span slot=\"rating\">\n",
      "<score-icon-critics sentiment=\"positive\" size=\"0.875\" style=\"width: 0.875rem; height: 0.875rem;\"></score-icon-critics>\n",
      "<span style=\"margin-top: 1.4px;\"></span>\n",
      "</span>\n",
      "---\n",
      "<span slot=\"rating\">\n",
      "<score-icon-critics sentiment=\"positive\" size=\"0.875\" style=\"width: 0.875rem; height: 0.875rem;\"></score-icon-critics>\n",
      "<span style=\"margin-top: 1.4px;\">5/5</span>\n",
      "</span>\n",
      "---\n",
      "<span slot=\"rating\">\n",
      "<score-icon-critics sentiment=\"positive\" size=\"0.875\" style=\"width: 0.875rem; height: 0.875rem;\"></score-icon-critics>\n",
      "<span style=\"margin-top: 1.4px;\">5/5</span>\n",
      "</span>\n",
      "---\n",
      "\n",
      "AUDIENCE PAGE - Found 10 cards\n",
      "First audience card slot='rating' raw HTML:\n",
      "<rating-stars-group score=\"5\" slot=\"rating\"></rating-stars-group>\n",
      "---\n",
      "<rating-stars-group score=\"5\" slot=\"rating\"></rating-stars-group>\n",
      "---\n",
      "<rating-stars-group score=\"5\" slot=\"rating\"></rating-stars-group>\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['WDM_SSL_VERIFY'] = '0'\n",
    "os.environ['WDM_TIMEOUT'] = '300'\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Check critic review card\n",
    "driver.get(\"https://www.rottentomatoes.com/m/parasite_2019/reviews\")\n",
    "time.sleep(8)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "cards = soup.find_all(\"review-card\")\n",
    "print(f\"CRITIC PAGE - Found {len(cards)} cards\")\n",
    "if cards:\n",
    "    print(\"First critic card slot='rating' raw HTML:\")\n",
    "    for card in cards[:3]:\n",
    "        rating = card.find(attrs={\"slot\": \"rating\"})\n",
    "        print(rating)\n",
    "        print(\"---\")\n",
    "\n",
    "# Check audience review card\n",
    "driver.get(\"https://www.rottentomatoes.com/m/parasite_2019/reviews/verified-audience\")\n",
    "time.sleep(8)\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "cards = soup.find_all(\"review-card\")\n",
    "print(f\"\\nAUDIENCE PAGE - Found {len(cards)} cards\")\n",
    "if cards:\n",
    "    print(\"First audience card slot='rating' raw HTML:\")\n",
    "    for card in cards[:3]:\n",
    "        rating = card.find(attrs={\"slot\": \"rating\"})\n",
    "        print(rating)\n",
    "        print(\"---\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc14db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
